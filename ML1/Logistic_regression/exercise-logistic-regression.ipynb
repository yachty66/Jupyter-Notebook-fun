{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# ML-Fundamentals - Logistic Regression and Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Table of Contents\n",
    "* [Introduction](#Introduction)\n",
    "* [Requirements](#Requirements) \n",
    "  * [Knowledge](#Knowledge) \n",
    "  * [Modules](#Python-Modules)\n",
    "* [Exercises - Multivariate Linear Regression](#Exercises---Multivariate-Linear-Regression)\n",
    "  * [Pen & Paper Exercises](#Pen-&-Paper-Exercises)\n",
    "  * [Data Generation](#Data-Generation)\n",
    "  * [Logistic Function](#Logistic-Function)\n",
    "  * [Cross-Entropy](#Cross-Entropy)\n",
    "  * [Loss Function](#Loss-Function)\n",
    "  * [Cost Function](#Cost-Function)\n",
    "  * [Gradient Descent](#Gradient-Descent)\n",
    "  * [Training and Evaluation](#Training-and-Evaluation)\n",
    "      * [Plot Data and Decision Boundary](#Plot-Data-and-Decision-Boundary)\n",
    "      * [Accuracy](#Accuracy)\n",
    "  * [Regularization](#Regularization)\n",
    "* [Summary and Outlook](#Summary-and-Outlook)\n",
    "* [Literature](#Literature) \n",
    "* [Licenses](#Licenses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this exercise you will implement the *logistic regression*. Opposed to the *linear regression*, the purpose of this model is not to predict a continuous value (e.g. the temperature tomorrow), but to predict a certain class: For example, whether it will rain tomorrow or not. During this exercise you will:\n",
    "\n",
    "1. Recap (and learn) the fundamentals of logistic regression: Costfunction, Gradient descent for logistic regression \n",
    "1. Implement the logistic function and plot it\n",
    "1. Implement the hypothesis using the logistic function\n",
    "1. Write a function to calculate the cross-entropy cost\n",
    "1. Implement the loss function using the hypothesis and cost\n",
    "1. Implement the gradient descent algorithm to train your model (optimizer) \n",
    "1. Visualize the decision boundary together with the data\n",
    "1. Calculate the accuracy of your model\n",
    "1. Extend your model with regularization\n",
    "1. Calculate the gradient for the loss function with cross-entropy cost (pen&paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Requirements\n",
    "### Knowledge\n",
    "\n",
    "You should have a basic knowledge of:\n",
    "- Logistic regression\n",
    "- Cross-entropy loss\n",
    "- Gradient descent\n",
    "- numpy\n",
    "- matplotlib\n",
    "\n",
    "Suitable sources for acquiring this knowledge are:\n",
    "- [Logistic Regression Notebook](http://christianherta.de/lehre/dataScience/machineLearning/basics/logistic-regression.php) by Christian Herta and corresponding [lecture slides](http://christianherta.de/lehre/dataScience/machineLearning/logisticRegression.pdf) (German)\n",
    "- [Regularization Notebook](http://christianherta.de/lehre/dataScience/machineLearning/basics/regularization.php) by Christian Herta and corresponding [lecture slides](http://christianherta.de/lehre/dataScience/machineLearning/regularization.pdf) (German)\n",
    "- Chapter 5.1 of [Deep Learning](http://www.deeplearningbook.org/contents/ml.html) by Ian Goodfellow \n",
    "- Some parts of chapter 1 and 3 of [Pattern Recognition and Machine Learning](https://www.microsoft.com/en-us/research/people/cmbishop/#!prml-book) by Christopher M. Bishop\n",
    "- [numpy quickstart](https://docs.scipy.org/doc/numpy-1.15.1/user/quickstart.html)\n",
    "- [Matplotlib tutorials](https://matplotlib.org/tutorials/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Python Modules\n",
    "\n",
    "By [deep.TEACHING](https://www.deep-teaching.org/) convention, all python modules needed to run the notebook are loaded centrally at the beginning. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# External Modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Exercise - Logistic Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pen & Paper Exercises\n",
    "\n",
    "#### Task\n",
    "\n",
    "Why is \n",
    "\n",
    "$$\n",
    "\\text{arg}\\max_x f(x) = \\text{arg}\\min_x \\left[ - \\log f(x) \\right] \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic model\n",
    "\n",
    "In logistic regression, the prediction of a learned model $h_\\Theta(\\vec x)$\n",
    "can be interpreted as the prediction that $\\vec x$ belongs to the positive class $1$:\n",
    "\n",
    "$$p(y=1\\mid \\vec x; \\Theta) = h_\\Theta(\\vec x)$$\n",
    "\n",
    "#### Task\n",
    "What is the probability of the negative class $p(y=0\\mid \\vec x; \\Theta)$ prediction (expressed with $h_\\Theta(\\vec x)$)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss\n",
    "\n",
    "\n",
    "The loss of an example $(\\vec x^{(i)}, y^{(i)})$ with target value $y^{(i)}=1$ is\n",
    "$$loss_{(\\vec x^{(i)}, 1)} (\\Theta) = - \\log p(y=1\\mid \\vec x; \\Theta)$$\n",
    "\n",
    "The loss of an example $(\\vec x^{(i)}, y^{(i)})$ with target value $y^{(i)}=0$ is\n",
    "$$loss_{(\\vec x^{(i)}, 0)} (\\Theta) = - \\log p(y=0\\mid \\vec x; \\Theta)$$\n",
    "\n",
    "So, $p(y=k\\mid \\vec x; \\Theta)$ is maximized for the target class $k$ \"by searching\n",
    "in the $\\Theta$-space\".  \n",
    "\n",
    "$p(y=k\\mid \\vec x; \\Theta)$ is called *likelihood* of $\\Theta$ (of one example $(\\vec x, y)$)\n",
    "if it is considered as a function of $\\Theta$. \n",
    "Note that the likelihood is a function of $\\Theta$.\n",
    "\n",
    "$\\mathcal L^{(i)}(\\Theta) = \\log p(y^{(i)}\\mid \\vec x^{(i)}; \\Theta)$ is the log-likelihood\n",
    "of $\\Theta$ for an example $i$.\n",
    "\n",
    "Why is $p(y=k\\mid \\vec x; \\Theta)$ not a probability with respect to $\\Theta$.\n",
    "Which property of a probability does not hold?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i.i.d. and log-likelihood for all data\n",
    "\n",
    "Note that the training data in logistic regression should be \n",
    "**i.i.d.** (independent and identically distributed):\n",
    "\n",
    "An simple example of an i.i.d. data set is the toin coss of a (marked) coin.\n",
    "Assume that the probability of head (class $y=1$) is $0.4$, i.e. $p(y=1)=0.4$.     \n",
    "The probability of getting two heads in two throws is $0.4 \\cdot 0.4$:\n",
    "- Each throw has the same distribution (here: $p(y=1)=0.4$. Each throw of the same coin is **identically distributed**\n",
    "- The throws are **independent**. If we get a head on the first throw the probability of\n",
    "getting a head on the second throw does not change.\n",
    "\n",
    "So, the probability factorizes: $p(y^{(1)}=1, y^{(2)}=1)=p(y^{(1)}=1)p(y^{(2)}=1)$\n",
    "\n",
    "For our classification problem:\n",
    "\n",
    "$p(\\mathcal D_y \\mid \\mathcal D_x; \\Theta) = \\prod_i p(y=y^{(i)}\\mid \\vec x^{(i)}; \\Theta)$ \n",
    "\n",
    "with \n",
    "- $\\mathcal D_x= \\{x^{(1)}, x^{(2)}, \\dots , x^{(m)}\\}$\n",
    "- $\\mathcal D_y= \\{y^{(1)}, y^{(2)}, \\dots , y^{(m)}\\}$\n",
    "- $\\mathcal D$ is the combination of $\\mathcal D_x$ with $\\mathcal D_y$:\n",
    "$\\mathcal D= \\{ (\\vec x^{(1)},y^{(1)}), (\\vec x^{(2)},y^{(2)}), \\dots , (\\vec x^{(m)},y^{(m)})\\}$. \n",
    "\n",
    "#### Task \n",
    "For the whole data set the log-likelihood $\\mathcal L_\\mathcal D(\\Theta)$ of a parameter set $\\Theta$ is \n",
    "$\\log p(\\mathcal D_y \\mid \\mathcal D_x; \\Theta)$).     \n",
    "Note: The (log-)likelihood $\\mathcal L_\\mathcal D(\\Theta)$ is a function of the parameters $\\Theta$.\n",
    "Never say the (log-)likelihood of the data.\n",
    "\n",
    "1. What is $\\mathcal L_\\mathcal D(\\Theta) = \\log p(\\mathcal D_y \\mid \\mathcal D_x; \\Theta)$ expressed by the $p(y^{(i)}\\mid \\vec x^{(i)}; \\Theta)$?\n",
    "\n",
    "2. What is the relation of the log-likelihood $\\mathcal L^{(i)}(\\Theta)$ (for the individual examples $(\\vec x^{(i)}, y^{(i)})$) \n",
    "to the log-likelihood $\\mathcal L_\\mathcal D(\\Theta)$ for the whole data set.\n",
    "\n",
    "  In logistic regression the cost function is the negative log-likelihood divided by the number of data examples $m$:\n",
    "\n",
    " $$J (\\Theta) = - \\frac{\\mathcal L_\\mathcal D(\\Theta)}{m}$$\n",
    "\n",
    "The average log-likelihood per data point.\n",
    "\n",
    "2. What is the relation of the (log-)likelihood with the cost function for logistic-regression? \n",
    "3. Derive the cost function of logistic-regression by using your result of 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "h_\\Theta(\\vec x^{(i)}) = p(1\\mid \\vec x^{(i)}; \\Theta)\n",
    "$$\n",
    "\n",
    "$$\n",
    "1 - h_\\Theta(\\vec x^{(i)}) = p(0\\mid \\vec x^{(i)}; \\Theta)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#### Derivative of the logistic function\n",
    "\n",
    "The sigmoid activation function is defined as $\\sigma (z) = \\frac{1}{1+\\exp(-z)}$ \n",
    "\n",
    "**Task:**\n",
    "\n",
    "Show that:\n",
    "$$\n",
    "\\frac{d \\sigma(z)}{d z} = \\sigma(z)(1-\\sigma(z))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task:\n",
    "\n",
    "Now show that:\n",
    "$$\n",
    "\\frac{\\partial \\sigma(z)}{\\partial \\theta_j} = \\sigma(z)(1-\\sigma(z)) \\cdot x_j\n",
    "$$\n",
    "\n",
    "\n",
    "with \n",
    "- $z=\\vec x'^T \\vec \\theta$\n",
    "\n",
    "and\n",
    "- $\\vec \\theta = (\\theta_0, \\theta_1, \\dots, \\theta_n)^T $\n",
    "- $\\vec x' = (x_0, x_1, \\dots, x_n)^T $\n",
    "\n",
    "\n",
    "Hint: Use the *chain rule of calculus*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Task:**\n",
    "\n",
    "Show from\n",
    "$$\n",
    "    \\frac{\\partial}{\\partial \\theta_j}  J(\\theta)  =  \n",
    "    \\frac{\\partial}{\\partial \\theta_j}  \\left( - \\frac{1}{m}  \\sum_{i=1}^{m} \n",
    "    \\left[  y^{(i)} \\log h_\\theta({\\vec x}^{(i)})+\n",
    "      (1 - y^{(i)}) \\log \\left( 1- h_\\theta({\\vec x}^{(i)})\\right) \\right] \\right)\n",
    "$$  \n",
    "that\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\theta_j}  J(\\theta)  =   \\frac{1}{m}\n",
    "     \\sum_{i=1}^{m} \\left( h_\\theta({\\vec x}^{(i)})- y^{(i)}\\right) x_j^{(i)}\n",
    "$$\n",
    "\n",
    "with the hypothesis $h_\\theta(\\vec x^{(i)}) = \\sigma(\\vec x'^T \\vec \\theta)$\n",
    "So, with our classification cost function (from the max-likelihood principle) the \n",
    "partial derivatives (components the gradient) has a simple form.\n",
    "\n",
    "**Hint:**\n",
    "\n",
    "1. Make use of your knowledge, that:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial h_\\theta(\\vec x^{(i)})}{\\partial \\theta_j} = h_\\theta(\\vec x^{(i)})(1-h_\\theta(\\vec x^{(i)})) \\cdot x_j\n",
    "$$\n",
    "2. and note that the chain rule for the derivative of the log is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\log(f(a))}{\\partial a} = \\frac{\\partial \\log(f(a))}{\\partial f} \\frac{\\partial f(a)}{\\partial a} =\n",
    "\\frac{1}{f(a)} \\frac{\\partial f(a)}{\\partial a}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Exercises\n",
    "\n",
    "For convenience and visualization, we will only use two features in this notebook, so we are still able to plot them together with the target class. But your implementation should also be capable of handling more (except the plots). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation\n",
    "\n",
    "First we will create some artificial data. For each class, we will generate the features with bivariate (2D) normal distribution;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f319d885d211>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# class 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# covariance matrix and mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcov0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmean0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# number of data points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# class 0:\n",
    "# covariance matrix and mean\n",
    "cov0 = np.array([[5,-4],[-4,4]])\n",
    "mean0 = np.array([2.,3])\n",
    "# number of data points\n",
    "m0 = 1000\n",
    "\n",
    "# class 1\n",
    "# covariance matrix\n",
    "cov1 = np.array([[5,-3],[-3,3]])\n",
    "mean1 = np.array([1.,1])\n",
    "# number of data points\n",
    "m1 = 1000\n",
    "\n",
    "# generate m gaussian distributed data points with\n",
    "# mean and cov.\n",
    "r0 = np.random.multivariate_normal(mean0, cov0, m0)\n",
    "r1 = np.random.multivariate_normal(mean1, cov1, m1)\n",
    "\n",
    "print(m0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(r0[...,0], r0[...,1], c='b', marker='*', label=\"class 0\")\n",
    "plt.scatter(r1[...,0], r1[...,1], c='r', marker='.', label=\"class 1\")\n",
    "plt.xlabel(\"x0\")\n",
    "plt.ylabel(\"x1\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "X = np.concatenate((r0,r1))\n",
    "y = np.ones(len(r0)+len(r1))\n",
    "y[:len(r0),] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Function\n",
    "\n",
    "For the logistic regression, we want the output of the hypothesis to be in the interval $]0, 1[$. This is done using the *logistic function* $\\sigma(.)$. The logistic function is also called *sigmoid function* in machine learning:\n",
    "\n",
    "**Task:**\n",
    "\n",
    "Implement the _logistic function_ and plot it in the interval of $[-10,10]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_function(x):\n",
    "    \"\"\" Applies the logistic function to x, element-wise. \"\"\"\n",
    "    raise NotImplementedError(\"You should implement this function\")\n",
    "### Insert code to plot the logistic function below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Hypothesis\n",
    "\n",
    "The hypothesis in logistic regression is defined by:\n",
    "\n",
    "$$\n",
    "h_\\Theta(\\vec x) = \\sigma(\\vec x'^T \\cdot \\vec \\theta)\n",
    "$$\n",
    "\n",
    "with:\n",
    "\n",
    "$$\n",
    "\\vec x^T = \\begin{pmatrix} \n",
    "x_1 & x_2 & \\ldots & x_n \\\\\n",
    "\\end{pmatrix}\n",
    "\\text{   and   }\n",
    "\\vec x'^T = \\begin{pmatrix} \n",
    "x_0=1 & x_1 & x_2 & \\ldots & x_n \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "or for the whole data set $X$ and $X'$\n",
    "\n",
    "$$\n",
    "X = \\begin{pmatrix} \n",
    "x_1^{(1)} & \\ldots & x_n^{(1)} \\\\\n",
    "x_1^{(2)} & \\ldots & x_n^{(2)} \\\\\n",
    "\\vdots &\\vdots &\\vdots \\\\\n",
    "x_1^{(m)} & \\ldots & x_n^{(m)} \\\\\n",
    "\\end{pmatrix}\n",
    "\\text{   and   }\n",
    "X' = \\begin{pmatrix} \n",
    "1 & x_1^{(1)} & \\ldots & x_n^{(1)} \\\\\n",
    "1 & x_1^{(2)} & \\ldots & x_n^{(2)} \\\\\n",
    "\\vdots &\\vdots &\\vdots &\\vdots \\\\\n",
    "1 & x_1^{(m)} & \\ldots & x_n^{(m)} \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    " - $n$ is the number of features\n",
    " - $m$ is the number of training data (examples)\n",
    " \n",
    " \n",
    "**Task:**\n",
    "\n",
    "Implement the logistic hypothesis using your implementation of the logistic function. `logistic_hypothesis` should return a function which accepts the training data $X$. Example usage:\n",
    "\n",
    "`>> theta = np.array([1.1, 2.0, -.9])`\n",
    "\n",
    "`>> h = logistic_hypothesis(theta) `\n",
    "\n",
    "`>> print(h(X))`\n",
    "\n",
    "**Note:** The training data was sampled with random noise, so the actual values of your h(X) may differ.\n",
    "\n",
    "`array([0.03587382, 0.0299963 , 0.97389774, ...,`\n",
    "\n",
    "**Hint:**\n",
    "\n",
    "You may of course also implement a helper function for transforming $X$ into $X'$ and use it inside the `lamda` function of `logistic_hypothesis`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_hypothesis(theta):\n",
    "    ''' Combines given list argument in a logistic equation and returns it as a function\n",
    "    \n",
    "    Args:\n",
    "        thetas: list of coefficients\n",
    "        \n",
    "    Returns:\n",
    "        lambda that models a logistc function based on thetas and x\n",
    "    '''\n",
    "    raise NotImplementedError(\"You should implement this function\")\n",
    "### Uncomment to test your implementation\n",
    "#theta = np.array([1.,2.,3.])\n",
    "#h = logistic_hypothesis(theta)\n",
    "#print(h(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-entropy\n",
    "\n",
    "The cross-entropy loss for a data point $({\\vec x}^{(i)}, y^{(i)})$ is defined by:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\text{loss}_{({\\vec x}^{(i)}, y^{(i)})}(\\vec \\theta) = -y^{(i)} \\cdot log(h_{\\Theta} ({\\vec x}^{(i)})) - (1-y^{(i)}) \\cdot log(1-h_\\Theta({\\vec x}^{(i)}))\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "with \n",
    "- the target class $y^{(i)} \\in \\{ 0, 1\\}$ of the $i$-th data point \n",
    "- the parameters $\\Theta$ packed in the vector $\\vec \\theta$.\n",
    "- $h_{\\Theta}({\\vec x}^{(i)})$ the predition for the feature vector of the $i$-th data point $\\vec x^{(i)}$ with the parameters $\\Theta$ (resp. $\\vec \\theta$)\n",
    "\n",
    "\n",
    "**Task:**\n",
    "\n",
    "Implement the cross-entropy cost. This is the sum of the losses of all data $(X, \\vec y)$.\n",
    "\n",
    "Your python function should return a function, which accepts the vector $\\vec \\theta$.\n",
    "This reflects the fact that $\\text{loss}(\\vec \\theta)$ is a function of the parameter (vector).\n",
    "\n",
    "The returned function should return the cost for each feature vector $\\vec x^{(i)}$ and target $y^{(i)}$. The length of the returned array of costs therefore has to be the same length as $m$ (number of data examples).    \n",
    "Example usage:\n",
    "\n",
    "`>> J = cross_entropy_loss(logistic_hypothesis, X, y)`\n",
    "\n",
    "`>> print(J(theta))`\n",
    "\n",
    "**Note:** The training data was sampled with random noise, so the actual values of your h(X) may differ.\n",
    "\n",
    "\n",
    "`array([ 7.3,  9.5, ....`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_costs(h, X, y):\n",
    "    ''' Implements cross-entropy as a function costs(theta) on given traning data \n",
    "    Args:\n",
    "        h: the hypothesis as function\n",
    "        x: features as 2D array with shape (m_examples, n_features)  \n",
    "        y: ground truth labels for given features with shape (m_examples)\n",
    "        \n",
    "    Returns:\n",
    "        lambda costs(theta) that models the cross-entropy for each x^i\n",
    "    '''\n",
    "    raise NotImplementedError(\"You should implement this function\")\n",
    "\n",
    "### Uncomment to test your implementation\n",
    "#theta = np.array([1.,2.,3.])\n",
    "#costs = cross_entropy_costs(logistic_hypothesis, X, y)\n",
    "#print(costs(theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "\n",
    "\\begin{equation}\n",
    "    J_{\\mathcal D}(\\vec \\theta)=\\frac{1}{m}\\sum_{i=1}^{m}\\left(\\text{loss}_{({\\vec x}^{(i)}, y^{(i)})}(\\Theta)\\right)\n",
    "\\end{equation}\n",
    "\n",
    "- with the training data $\\mathcal D = \\{ (\\vec x^{(1)}, y^{(1)}), \\dots,  (\\vec x^{(m)}, y^{(m)}) \\}$ \n",
    "\n",
    "**Task:**\n",
    "\n",
    "Now implement the loss function $J$, which calculates the mean costs for the whole training data $X$. Your python function should return a function, which accepts the vector $\\vec \\theta$.\n",
    "\n",
    "**Note:** You can ignore the parameter `lambda_reg` for now, it is a hyperparameter for regularization. In a later exercise, you may revisit your implementation and implement regularization if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mean_cross_entropy_costs(X, y, hypothesis, cost_func, lambda_reg=0.1):\n",
    "    ''' Implements mean cross-entropy as a function J(theta) on given traning data \n",
    "    \n",
    "    Args:\n",
    "        X: features as 2D array with shape (m_examples, n_features)  \n",
    "        y: ground truth labels for given features with shape (m_examples)\n",
    "        hypothesis: the hypothesis as function\n",
    "        cost_func: cost function\n",
    "        \n",
    "    Returns:\n",
    "        lambda J(theta) that models the mean cross-entropy\n",
    "    '''\n",
    "    raise NotImplementedError(\"You should implement this\")\n",
    "    \n",
    "### Uncomment to test your implementation\n",
    "#theta = np.array([1.,2.,3.])\n",
    "#J = mean_cross_entropy_costs(X,y, logistic_hypothesis, cross_entropy_costs, 0.1)\n",
    "#print(J(theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###  Gradient Descent\n",
    "\n",
    "A short recap, the gradient descent algorithm is a first-order iterative optimization for finding a minimum of a function. From the current position in a (cost) function, the algorithm steps proportional to the negative of the gradient and repeats this until it reaches a local or global minimum and determines.\n",
    "Stepping proportional means that it does not go entirely in the direction of the negative gradient, but scaled by a fixed value $\\alpha$ also called the learning rate. Implementing the following formalized update rule is the core of the optimization process:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\vec \\theta_{new} \\leftarrow \\vec \\theta_{{old}} - \\alpha  \\vec \\nabla_\\Theta J(\\vec \\theta_{old})\n",
    "\\end{equation}\n",
    "\n",
    "**Task:**\n",
    "\n",
    "Implement the function to update all $\\theta$ values (in a vectorized way).\n",
    "\n",
    "**Note:** You can ignore the parameter `lambda_reg` for now, it is a hyperparameter for regularization. In a later exercise, you may revisit your implementation and implement regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_new_theta(X, y, theta, learning_rate, hypothesis, lambda_reg=0.1):\n",
    "    ''' Updates learnable parameters theta \n",
    "    \n",
    "    The update is done by calculating the partial derivities of \n",
    "    the cost function including the linear hypothesis. The \n",
    "    gradients scaled by a scalar are subtracted from the given \n",
    "    theta values.\n",
    "    \n",
    "    Args:\n",
    "        X: 2D numpy array of x values\n",
    "        y: array of y values corresponding to x\n",
    "        theta: current theta values\n",
    "        learning_rate: value to scale the negative gradient  \n",
    "        hypothesis: the hypothesis as function\n",
    "        \n",
    "        \n",
    "    Returns:\n",
    "        theta: Updated theta_0\n",
    "    '''\n",
    "    raise NotImplementedError(\"You should implement this\")\n",
    "\n",
    "### Uncomment to test your implementation\n",
    "#theta = np.array([1.,2.,3.])\n",
    "#theta = compute_new_theta(X, y, theta, .1, logistic_hypothesis, .1)\n",
    "#print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Using the `compute_new_theta` method, you can now implement the gradient descent algorithm. Iterate over the update rule to find the values for $\\theta$ that minimize our cost function $J_D(\\theta)$. This process is often called training of a machine learning model. \n",
    "\n",
    "**Task:**\n",
    "- Implement the function for the gradient descent.\n",
    "- Create a history of all theta and cost values and return them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, theta, learning_rate, num_iters, lambda_reg=0.1):\n",
    "    ''' Minimize theta values of a logistic model based on cross-entropy cost function\n",
    "    \n",
    "    Args:\n",
    "        X: 2D numpy array of x values\n",
    "        y: array of y values corresponding to x\n",
    "        theta: current theta values\n",
    "        learning_rate: value to scale the negative gradient  \n",
    "        num_iters: number of iterations updating thetas\n",
    "        lambda_reg: regularization strength\n",
    "        cost_function: python function for computing the cost\n",
    "        \n",
    "    Returns:\n",
    "        history_cost: cost after each iteration\n",
    "        history_theta: Updated theta values after each iteration\n",
    "    '''\n",
    "    raise NotImplementedError(\"You should implement this\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluation\n",
    "\n",
    "**Task:**\n",
    "\n",
    "Choose an appropriate learning rate, number of iterations and initial theta values and start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-1a8b0be84971>:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 1. / (1. + np.exp(-x))\n",
      "<ipython-input-9-1a7b7be352f6>:14: RuntimeWarning: divide by zero encountered in log\n",
      "  return lambda theta: -y * np.log(h(theta)(X)) - (1-y) * np.log(1. - h(theta)(X))\n",
      "<ipython-input-9-1a7b7be352f6>:14: RuntimeWarning: invalid value encountered in multiply\n",
      "  return lambda theta: -y * np.log(h(theta)(X)) - (1-y) * np.log(1. - h(theta)(X))\n"
     ]
    }
   ],
   "source": [
    "# TODO: Assign sensible values\n",
    "alpha = 42\n",
    "theta = np.array([42, -100, 10e5])\n",
    "num_iters = 1234\n",
    "history_cost, history_theta = gradient_descent(X, y, theta, alpha, num_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the training has finished we can visualize our results.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "Plot the costs over the iterations. Your plot should look similar to this one:\n",
    "\n",
    "<img src=\"https://gitlab.com/deep.TEACHING/educational-materials/raw/dev/media/klaus/exercise-multivariate-linear-regression-costs.png\" width=\"512\" alt=\"internet connection needed\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def plot_progress(costs):\n",
    "    \"\"\" Plots the costs over the iterations\n",
    "    Args:\n",
    "        costs: history of costs\n",
    "    \"\"\"\n",
    "    raise NotImplementedError(\"You should implement this!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "costs before the training:\t  7.09875845248717\n",
      "costs after the training:\t  0.289131417345017\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_progress(history_cost)\n",
    "print(\"costs before the training:\\t \", history_cost[0])\n",
    "print(\"costs after the training:\\t \", history_cost[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Data and Decision Boundary \n",
    "\n",
    "**Task:**\n",
    "\n",
    "Now plot the decision boundary (a straight line in this case) together with the data.         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.44057918, -0.88113422, -1.1449211 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert your code to plot below\n",
    "theta_hist[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy\n",
    "\n",
    "The logistic hypothesis outputs a value in the interval $]0,1[$. We want to map this value to one specific class i.e. $0$ or $1$, so we apply a threshold known as the decision boundary: If the predicted value is < 0.5, the class is 0, otherwise it is 1.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "1. Calculate the accuracy of your final classifier. The accuracy is the proportion of the correctly classified data.\n",
    "2. Why will the accuracy never reach 100% using this model and this data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Insert you code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "\n",
    "**Task:**\n",
    "    \n",
    "Extend your implementation with a regularization term $\\lambda$ by adding it as argument to the functions `mean_cross_entropy_costs`, `compute_new_theta` and `gradient_descent`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Summary and Outlook\n",
    "\n",
    "During this exercise you learned about logistic regression and used it to perform binary classification on multidimensional data. You should be able to answer the following questions:\n",
    "* How can you interpret the output of the logistic function?\n",
    "* For which type of problem do you use linear regression and for which type of problem do you use logistic regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Licenses\n",
    "\n",
    "### Notebook License (CC-BY-SA 4.0)\n",
    "\n",
    "*The following license applies to the complete notebook, including code cells. It does however not apply to any referenced external media (e.g., images).*\n",
    "\n",
    "Exercise: Logistic Regression and Regularization <br/>\n",
    "by Christian Herta, Klaus Strohmenger <br/>\n",
    "is licensed under a [Creative Commons Attribution-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-sa/4.0/).<br/>\n",
    "Based on a work at https://gitlab.com/deep.TEACHING.\n",
    "\n",
    "\n",
    "### Code License (MIT)\n",
    "\n",
    "*The following license only applies to code cells of the notebook.*\n",
    "\n",
    "Copyright 2018 Christian Herta, Klaus Strohmenger\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
