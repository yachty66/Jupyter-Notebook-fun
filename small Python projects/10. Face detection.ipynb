{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05d6f5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://www.thepythoncode.com/article/gender-detection-using-opencv-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b84d17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/maxhager/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - tk\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2022.4.26  |       hecd8cb5_0         132 KB  anaconda\n",
      "    certifi-2021.10.8          |   py39hecd8cb5_2         156 KB  anaconda\n",
      "    conda-4.12.0               |   py39hecd8cb5_0        16.9 MB  anaconda\n",
      "    openssl-1.1.1n             |       hca72f7f_0         3.5 MB  anaconda\n",
      "    tk-8.6.11                  |       h7bc2e8c_0         3.3 MB  anaconda\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        24.0 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2021.10.~ --> anaconda::ca-certificates-2022.4.26-hecd8cb5_0\n",
      "  tk                                      8.6.10-hb0a8c7a_0 --> 8.6.11-h7bc2e8c_0\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi            conda-forge::certifi-2021.10.8-py39h6~ --> anaconda::certifi-2021.10.8-py39hecd8cb5_2\n",
      "  conda              conda-forge::conda-4.12.0-py39h6e9494~ --> anaconda::conda-4.12.0-py39hecd8cb5_0\n",
      "  openssl            conda-forge::openssl-1.1.1n-h6c3fc93_0 --> anaconda::openssl-1.1.1n-hca72f7f_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "certifi-2021.10.8    | 156 KB    | ##################################### | 100% \n",
      "conda-4.12.0         | 16.9 MB   | ##################################### | 100% \n",
      "tk-8.6.11            | 3.3 MB    | ##################################### | 100% \n",
      "openssl-1.1.1n       | 3.5 MB    | ##################################### | 100% \n",
      "ca-certificates-2022 | 132 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c anaconda tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a0b1422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.5.64-cp36-abi3-macosx_10_15_x86_64.whl (46.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 46.3 MB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/maxhager/opt/anaconda3/lib/python3.9/site-packages (1.20.3)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.5.64\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94e47984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "375ffbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "GENDER_MODEL = \"/Users/maxhager/Downloads/deploy_gender.prototxt\"\n",
    "# The gender model pre-trained weights\n",
    "# https://drive.google.com/open?id=1AW3WduLk1haTVAxHOkVS_BEzel1WXQHP\n",
    "GENDER_PROTO = \"/Users/maxhager/Downloads/gender_net.caffemodel\"\n",
    "print()\n",
    "# Each Caffe Model impose the shape of the input image also image preprocessing is required like mean\n",
    "# substraction to eliminate the effect of illunination changes\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "# Represent the gender classes\n",
    "GENDER_LIST = ['Male', 'Female']\n",
    "# https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt\n",
    "FACE_PROTO = \"/Users/maxhager/Downloads/deploy.prototxt.txt\"\n",
    "# https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20180205_fp16/res10_300x300_ssd_iter_140000_fp16.caffemodel\n",
    "FACE_MODEL = \"/Users/maxhager/Downloads/res10_300x300_ssd_iter_140000_fp16.caffemodel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15d8f3aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) /Users/runner/work/opencv-python/opencv-python/opencv/modules/dnn/src/caffe/caffe_io.cpp:1126: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"/Users/maxhager/Downloads/deploy.prototxt.txt\" in function 'ReadProtoFromTextFile'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0n/n106l5rn7cb6yw8038g17vcm0000gn/T/ipykernel_36631/4103839119.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load face Caffe model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mface_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadNetFromCaffe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFACE_PROTO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFACE_MODEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load gender prediction model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgender_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadNetFromCaffe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGENDER_MODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGENDER_PROTO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.5) /Users/runner/work/opencv-python/opencv-python/opencv/modules/dnn/src/caffe/caffe_io.cpp:1126: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"/Users/maxhager/Downloads/deploy.prototxt.txt\" in function 'ReadProtoFromTextFile'\n"
     ]
    }
   ],
   "source": [
    "# load face Caffe model\n",
    "face_net = cv2.dnn.readNetFromCaffe(FACE_PROTO, FACE_MODEL)\n",
    "# Load gender prediction model\n",
    "gender_net = cv2.dnn.readNetFromCaffe(GENDER_MODEL, GENDER_PROTO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18c8bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_faces(frame, confidence_threshold=0.5):\n",
    "    # convert the frame into a blob to be ready for NN input\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), (104, 177.0, 123.0))\n",
    "    # set the image as input to the NN\n",
    "    face_net.setInput(blob)\n",
    "    # perform inference and get predictions\n",
    "    output = np.squeeze(face_net.forward())\n",
    "    # initialize the result list\n",
    "    faces = []\n",
    "    # Loop over the faces detected\n",
    "    for i in range(output.shape[0]):\n",
    "        confidence = output[i, 2]\n",
    "        if confidence > confidence_threshold:\n",
    "            box = output[i, 3:7] * \\\n",
    "                np.array([frame.shape[1], frame.shape[0],\n",
    "                         frame.shape[1], frame.shape[0]])\n",
    "            # convert to integers\n",
    "            start_x, start_y, end_x, end_y = box.astype(np.int)\n",
    "            # widen the box a little\n",
    "            start_x, start_y, end_x, end_y = start_x - \\\n",
    "                10, start_y - 10, end_x + 10, end_y + 10\n",
    "            start_x = 0 if start_x < 0 else start_x\n",
    "            start_y = 0 if start_y < 0 else start_y\n",
    "            end_x = 0 if end_x < 0 else end_x\n",
    "            end_y = 0 if end_y < 0 else end_y\n",
    "            # append to our list\n",
    "            faces.append((start_x, start_y, end_x, end_y))\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924ae2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_img(title, img):\n",
    "    \"\"\"Displays an image on screen and maintains the output until the user presses a key\"\"\"\n",
    "    # Display Image on screen\n",
    "    cv2.imshow(title, img)\n",
    "    # Mantain output until user presses a key\n",
    "    cv2.waitKey(0)\n",
    "    # Destroy windows when user presses a key\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7931cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_font_scale(text, width):\n",
    "    \"\"\"Determine the optimal font scale based on the hosting frame width\"\"\"\n",
    "    for scale in reversed(range(0, 60, 1)):\n",
    "        textSize = cv2.getTextSize(text, fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=scale/10, thickness=1)\n",
    "        new_width = textSize[0][0]\n",
    "        if (new_width <= width):\n",
    "            return scale/10\n",
    "    return 1\n",
    "\n",
    "# from: https://stackoverflow.com/questions/44650888/resize-an-image-without-distortion-opencv\n",
    "def image_resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "    # if both the width and height are None, then return the\n",
    "    # original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    # check to see if the width is None\n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the\n",
    "        # dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # calculate the ratio of the width and construct the\n",
    "        # dimensions\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "    # resize the image\n",
    "    return cv2.resize(image, dim, interpolation = inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026eee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def predict_gender(imag):\n",
    "    \"\"\"Predict the gender of the faces showing in the image\"\"\"\n",
    "    # Read Input Image\n",
    "    img = cv2.imread(imag)\n",
    "    frame_height, frame_width, _ = img.shape\n",
    "    # resize the image, uncomment if you want to resize the image\n",
    "    #img = cv2.resize(img, (frame_width, frame_height))\n",
    "    # Take a copy of the initial image and resize it\n",
    "    frame = img.copy()\n",
    "    print(frame.shape[1])\n",
    "    if frame.shape[1] > frame_width:\n",
    "        frame = image_resize(frame, width=frame_width)\n",
    "    # predict the faces\n",
    "    faces = get_faces(frame)\n",
    "    # Loop over the faces detected\n",
    "    # for idx, face in enumerate(faces):\n",
    "    for i, (start_x, start_y, end_x, end_y) in enumerate(faces):\n",
    "        face_img = frame[start_y: end_y, start_x: end_x]\n",
    "        # image --> Input image to preprocess before passing it through our dnn for classification.\n",
    "        # scale factor = After performing mean substraction we can optionally scale the image by some factor. (if 1 -> no scaling)\n",
    "        # size = The spatial size that the CNN expects. Options are = (224*224, 227*227 or 299*299)\n",
    "        # mean = mean substraction values to be substracted from every channel of the image.\n",
    "        # swapRB=OpenCV assumes images in BGR whereas the mean is supplied in RGB. To resolve this we set swapRB to True.\n",
    "        blob = cv2.dnn.blobFromImage(image=face_img, scalefactor=1.0, size=(\n",
    "            227, 227), mean=MODEL_MEAN_VALUES, swapRB=False, crop=False)\n",
    "        # Predict Gender\n",
    "        gender_net.setInput(blob)\n",
    "        gender_preds = gender_net.forward()\n",
    "        i = gender_preds[0].argmax()\n",
    "        gender = GENDER_LIST[i]\n",
    "        gender_confidence_score = gender_preds[0][i]\n",
    "        # Draw the box\n",
    "        label = \"{}-{:.2f}%\".format(gender, gender_confidence_score*100)\n",
    "        print(label)\n",
    "        yPos = start_y - 15\n",
    "        while yPos < 15:\n",
    "            yPos += 15\n",
    "        # get the font scale for this image size\n",
    "        optimal_font_scale = get_optimal_font_scale(label,((end_x-start_x)+25))\n",
    "        box_color = (255, 0, 0) if gender == \"Male\" else (147, 20, 255)\n",
    "        cv2.rectangle(frame, (start_x, start_y), (end_x, end_y), box_color, 2)\n",
    "        # Label processed image\n",
    "        cv2.putText(frame, label, (start_x, yPos),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, optimal_font_scale, box_color, 2)\n",
    "\n",
    "        # Display processed image\n",
    "    display_img(\"Gender Estimator\", frame)\n",
    "    # uncomment if you want to save the image\n",
    "    # cv2.imwrite(\"output.jpg\", frame)\n",
    "    # Cleanup\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5925d923",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbfc424",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Parsing command line arguments entered by user\n",
    "    import sys\n",
    "    predict_gender(\"/Users/maxhager/Downloads/test2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5828422b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ba4de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetWithDogs = \"/Users/Username/Downloads/datasetWithDogs\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd95ad4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
